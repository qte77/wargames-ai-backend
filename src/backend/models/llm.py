"""Pydantic models for LLM interactions.

This module defines the data models used for LLM API requests and responses,
following the OpenAI ChatCompletions API format for consistency.
"""

from typing import Any, Literal

from pydantic import BaseModel, Field


class ChatMessage(BaseModel):
    """A single chat message in the conversation.

    Attributes:
        role: The role of the message sender (user, assistant, system).
        content: The content of the message.
        name: Optional name of the message sender.
    """

    role: Literal["user", "assistant", "system"]
    content: str
    name: str | None = None


class ChatRequest(BaseModel):
    """Request model for chat completions.

    Attributes:
        model: The model to use for completion.
        messages: List of messages in the conversation.
        temperature: Sampling temperature (0.0 to 2.0).
        max_tokens: Maximum tokens in the response.
        stream: Whether to stream the response.
        user: Optional user identifier for tracking.
    """

    model: str
    messages: list[ChatMessage]
    temperature: float | None = Field(default=0.7, ge=0.0, le=2.0)
    max_tokens: int | None = Field(default=4096, ge=1, le=8192)
    stream: bool | None = False
    user: str | None = None


class ChatChoice(BaseModel):
    """A single choice in the chat completion response.

    Attributes:
        index: The index of this choice.
        message: The message generated by the model.
        finish_reason: The reason the model stopped generating.
    """

    index: int
    message: ChatMessage
    finish_reason: str | None


class ChatUsage(BaseModel):
    """Token usage information for the chat completion.

    Attributes:
        prompt_tokens: Number of tokens in the prompt.
        completion_tokens: Number of tokens in the completion.
        total_tokens: Total number of tokens used.
    """

    prompt_tokens: int
    completion_tokens: int
    total_tokens: int


class ChatResponse(BaseModel):
    """Response model for chat completions.

    Attributes:
        id: Unique identifier for the completion.
        object: The object type (always "chat.completion").
        created: Unix timestamp of when the completion was created.
        model: The model used for the completion.
        choices: List of completion choices.
        usage: Token usage information.
    """

    id: str
    object: str
    created: int
    model: str
    choices: list[ChatChoice]
    usage: ChatUsage | None = None


class ModelInfo(BaseModel):
    """Information about an available model.

    Attributes:
        id: The model identifier.
        object: The object type (always "model").
        created: Unix timestamp of when the model was created.
        owned_by: The organization that owns the model.
        display_name: Human-readable name for UI display.
        description: Model description.
        max_tokens: Maximum tokens supported.
    """

    id: str
    object: str = "model"
    created: int
    owned_by: str
    display_name: str | None = None
    description: str | None = None
    max_tokens: int | None = None


class ModelsResponse(BaseModel):
    """Response model for listing available models.

    Attributes:
        object: The object type (always "list").
        data: List of available models.
    """

    object: str = "list"
    data: list[ModelInfo]


class LLMHealthStatus(BaseModel):
    """Health status response for LLM service.

    Attributes:
        status: Health status (healthy, unhealthy, degraded).
        available_models: Number of models with valid API keys.
        missing_keys: List of missing API key environment variables.
        message: Human-readable status message.
        details: Additional status details.
    """

    status: Literal["healthy", "unhealthy", "degraded"]
    available_models: int
    missing_keys: list[str]
    message: str
    details: dict[str, Any] | None = None


class ErrorDetail(BaseModel):
    """Error detail information.

    Attributes:
        message: Human-readable error message.
        type: Error type identifier.
        param: Parameter that caused the error, if applicable.
        code: Error code, if applicable.
    """

    message: str
    type: str
    param: str | None = None
    code: str | None = None


class ErrorResponse(BaseModel):
    """Error response model.

    Attributes:
        error: Error details.
    """

    error: ErrorDetail
